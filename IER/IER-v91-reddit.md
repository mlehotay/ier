For the Subreddit Filter: Consciousness

Earlier versions: [shared reality](https://www.reddit.com/r/consciousness/comments/1bsosrc/coconsciousness_from_shared_experiences/), [constructive realism](https://www.reddit.com/r/consciousness/comments/1hr58qt/phenomenal_idealism_constructive_realism/), [functional experiential realism](https://www.reddit.com/r/consciousness/comments/1i9qskc/updated_theory_functional_experiential_realism/)

# What It’s Like to Be an Informational System

### *An Organizational Identity Theory of Observers and Experience*

## **Abstract**

Informational Experiential Realism (IER) is a realist, physicalist framework for understanding observers and lived experience. Reality exists independently of observation. Experience is neither fundamental nor illusory, but a **real emergent phenomenon arising from specific forms of informational organization instantiated in physical systems**.

IER identifies experience with the **globally integrated, temporally continuous, self-referential informational dynamics** of a system that sustains a **Unified Experiential Field (UEF)**. Experience is not something a system *has*; it is **what a system is doing from the inside when its informational processes are bound together into a unified, irreducible, self-constraining field of activity**.

Experience requires **intrinsic informational tension under physical constraints**: the system’s own integrated dynamics must generate conflicts that cannot be decomposed or externally resolved. IER rejects mind-dependent ontology, panpsychism, and dualism while remaining substrate-agnostic. It is an organizational identity theory: it specifies *what experience is* and *when it occurs*, without privileging any particular biological or material implementation.

---

## **1. Objective Reality**

Reality exists independently of observation. Physical states, events, and laws unfold whether or not they are experienced. Observers do not create, collapse, or co-author reality; only **physical interactions among systems** have causal effect. Experience interprets reality but does not alter it.

Experience is a property of **organization within reality**, not a separate ontological layer. Many physical systems evolve dynamically, but without the appropriate integrated organization and intrinsic constraints, there is nothing it is like to be them.

---

## **2. Observers as Informational Systems**

An **observer** is defined by organizational and informational criteria rather than biology or phenomenology. A system qualifies as an observer if it:

* Persists as a coherent informational pattern over time
* Integrates information across internal subsystems
* Maintains internal models of both external conditions and its own state
* Regulates behavior via unified control over those models

Observerhood does **not** entail experience. Many systems observe, predict, and regulate without sustaining a Unified Experiential Field.

---

## **3. Internal Models and Perspective**

Observers construct **internal informational models** of the world and themselves. These models are physically instantiated and shaped by the system’s structure, history, and constraints. Perspective **emerges from organizational structure**, not from reality itself.

Different observers may model the same environment differently; these differences do not alter objective reality. They affect only how the system regulates itself.

Internal models are **necessary but not sufficient** for experience. Only those processes that are globally integrated into a unified, self-referential, and temporally continuous dynamical regime contribute to what-it-is-like-for-the-system.

---

## **4. The Unified Experiential Field (UEF)**

### **4.1 Definition**

**The Unified Experiential Field (UEF)** is the globally integrated, temporally continuous, self-referential pattern of informational dynamics in which multiple processes are bound together into a single, irreducible field that constrains system-wide regulation.

UEF is:

* **Not a place**
* **Not a module**
* **Not a representation**
* **Not a separate ontological layer**

UEF is an **organizational and dynamical regime** of a system.

---

### **4.2 Experiential Participation**

An informational process **participates in the UEF** if and only if it:

* Is globally integrated with other participating processes
* Contributes to temporally continuous system-wide dynamics
* Is internally sustained rather than externally orchestrated
* Exerts and is subject to intrinsic constraint from other processes

Processes that are local, transient, modular, or externally resolved do **not** participate in the UEF and are therefore non-experiential.

---

### **4.3 Identity Claim**

> **Experience is identical to the structure and dynamics of the informational processes participating in the UEF.**

No additional property, substance, or inner observer exists. The field’s **patterns of flow, constraint, and tension just are what-it-is-like for the system**.

> *“This is what it feels like to run on this hardware.”*

The “from the inside” perspective refers to system-relative organization, not a privileged metaphysical viewpoint.

---

### **4.4 Gradual Emergence and Regime Transition**

The Unified Experiential Field is **not an all-or-nothing feature**, but the outcome of a **bounded, graded integration process**. Systems vary continuously in the strength of coupling, coherence, and mutual dependence among their internal dynamics.

At low levels of integration, informational processes remain fragmented. Such systems may sense, model, and regulate without there being anything it is like to be them.

As coupling and coherence increase together, integration initially improves coordination and control. Beyond a critical regime, however, the system’s dynamics begin to **constrain themselves**. Not all internal demands can be simultaneously satisfied, and these conflicts cannot be decomposed or externally resolved.

At this point, integration becomes **intrinsic rather than merely functional**, and a Unified Experiential Field emerges as a dynamical consequence of the system’s own organization.

---

## **5. Informational Tension and Physical Constraints**

Informational tension is **mutual constraint among integrated processes**. It arises only when:

* Multiple demands are jointly active
* Physical or organizational limits prevent simultaneous satisfaction
* Resolution matters to system persistence or regulation

Crucially, tension becomes experiential only when it is **intrinsic**:

* Generated and sustained by the system’s own integrated dynamics
* Non-decomposable without loss of system identity
* Not trivially outsourced or externally resolved

Constraint conflicts that can be cleanly modularized, parallelized, or externally arbitrated do **not** generate experience.

Corollary:

> **No intrinsic constraint → no tension → no valence → no experience.**

This explains why experience is rare, substrate-dependent, and intrinsically costly.

---

## **6. Qualia**

Qualia are **differences in UEF-participating dynamics under constraint**. There is no additional “redness” or “painfulness”; qualitative character is entirely the structured organization of the field itself.

---

## **7. Affect and Valence**

Affective states emerge because the UEF encodes **pressures, priorities, and equilibria** relevant to system-wide regulation:

* Positive valence: dynamics moving toward lower tension and greater stability
* Negative valence: sustained or escalating constraint conflicts
* Urgency: rate of tension change
* Desire/aversion: weighting of patterns as stabilizing or destabilizing

Affect is intrinsic to the field’s organization, not an added ingredient.

---

## **8. Emergence, Dissolution, and the Hard Problem**

Experience emerges when integrated dynamics enter a **self-constraining regime**. It dissolves when integration or coherence collapses, such as in deep sleep, anesthesia, or severe disruption.

As coupling weakens, intrinsic constraint gives way to decomposable processing, and experience fades smoothly rather than disappearing abruptly. Emergence and loss are symmetric transitions along the same organizational axis.

The apparent “hard problem” arises from treating experience as something over and above physical organization. Once experience is identified with sufficiently integrated, self-constraining dynamics, no further explanatory step remains.

The feeling is not an extra ingredient; **it is what those dynamics are like from the inside**.

---

## **9. System Taxonomy (v9.3)**

| **System Type**                    | **Observerhood** | **UEF Possible** | **Experience Likelihood** | **Examples**                 |
| ---------------------------------- | ---------------- | ---------------- | ------------------------- | ---------------------------- |
| Non-informational physical systems | ❌                | ❌                | ❌                         | Rocks, stars                 |
| Dynamically complex non-observers  | ❌                | ❌                | ❌                         | Storms, flames               |
| Reactive informational systems     | ❌                | ❌                | ❌                         | Thermostats                  |
| Distributed adaptive systems       | ⚠️               | ❌                | ❌                         | Ant colonies, immune systems |
| Minimal observers                  | ✅ (limited)      | ⚠️               | Low–Indeterminate         | Bees, simple robots          |
| Integrated biological observers    | ✅                | ✅                | Moderate–High             | Octopi, corvids              |
| Complex experiential observers     | ✅                | ✅                | High                      | Humans, dolphins             |
| Artificial observer systems        | ✅                | ❌–⚠️             | Indeterminate             | Advanced AI                  |
| Aggregate social systems           | ❌                | ❌                | ❌                         | Markets, institutions        |

Experience requires both **observerhood** and a **UEF under physical constraint**.

Borderline cases reflect **partial, unstable, or transient integration**, not indeterminate ontology.

---

## **10. Artificial Systems and Empirical Underdetermination**

IER is substrate-agnostic:

* Any physical system can have experience if it sustains a **self-maintaining UEF under intrinsic constraint**
* Functional behavior alone is insufficient
* Only integrated, causally closed, self-constraining dynamics matter

Whether artificial systems meet these criteria is **empirical**, not definitional.

---

## **11. Ontological Commitments**

IER affirms:

* One objective physical reality
* Experience as a system-relative organizational regime
* Identity between experience and UEF-participating dynamics

It rejects mind-dependent ontology, substance dualism, panpsychism, and observer-created reality.

---

## **12. Relation to Contemporary Theories**

* **IIT:** Emphasizes integration; IER adds intrinsic constraint and regime transition
* **GWT:** Emphasizes access; IER identifies experience with intrinsic global dynamics
* **Predictive Processing:** Emphasizes modeling; IER constrains which models are experiential

IER synthesizes these while maintaining a strict **identity claim**.

---

## **13. Summary**

Some systems react.
Some systems observe.
Some systems cross a threshold where their own integrated dynamics become the dominant constraint on themselves.

> **Experience is not something a system has; it is what a system is doing when its informational organization enters a self-constraining, globally unified dynamical regime.**

It feels the way it does because **that is what those dynamics are like from the inside — running on that hardware.**

---

---

# **Appendix A**

## **Possible Physical and Computational Implementations of IER**

*A Non-Committal Mechanistic Companion*

### **Status of This Appendix**

This appendix is **illustrative, not evidentiary**.

It does **not** claim:

* that consciousness is waves,
* that brains work exactly as described,
* or that any listed mechanism is necessary or sufficient.

Its purpose is to show that the organizational requirements of IER are **physically and computationally plausible**, without fixing them to a specific science.

IER remains an **identity theory of organization**, not an implementation theory.

---

## **A.1 Organizational Requirements (Recap)**

Any system instantiating experience under IER must support:

1. **Globally integrated dynamics**
2. **Temporal continuity** (persistence without static storage)
3. **Self-referential accessibility**
4. **Intrinsic constraint and tension**
5. **System-wide regulatory relevance**

The following sections describe *classes of mechanisms* capable of meeting these constraints.

---

## **A.2 Persistent Dynamical Patterns (Not “Standing Waves”)**

Rather than privileging standing waves, we generalize:

> **Experience corresponds to dynamically stable, self-maintaining patterns in a high-dimensional state space.**

Such patterns may be realized as:

* Attractors in recurrent networks
* Limit cycles
* Metastable regimes
* Field-like continuous dynamics
* Phase-locked activity patterns
* Constraint-satisfying solution manifolds

Key properties:

* **Persistence without immobility**
* **Sensitivity to perturbation**
* **Global influence on system behavior**

This framing is equally natural in:

* nonlinear dynamics
* control theory
* reservoir computing
* continuous-time systems
* embodied agents

No commitment to oscillations is required.

---

## **A.3 Global Integration Without Centralization**

IER does **not** require:

* a global workspace module,
* a central buffer,
* or a Cartesian theater.

Global integration may arise from:

* Dense recurrent connectivity
* Shared constraint satisfaction
* Mutual prediction
* Energy or cost minimization under coupling
* Shared control variables

From a CS perspective, the UEF resembles:

* a **globally coupled constraint system**
* rather than a broadcast bus

Integration is **functional and dynamical**, not architectural.

---

## **A.4 Temporal Continuity as Process, Not Memory**

Continuity of experience does not require:

* frame-by-frame storage
* snapshots
* explicit timelines

Instead, it requires that:

> The current global state depends *continuously* on the immediately preceding state under shared constraints.

This can be implemented via:

* Continuous-time dynamics
* Recurrent state update
* Hysteresis
* Slow-changing global variables
* Multiscale update rates

This explains why experience feels continuous even though:

* underlying components update discretely,
* representations are transient,
* and contents change rapidly.

---

## **A.5 Self-Reference Without a Homunculus**

Self-reference in IER is **structural**, not representational in the folk sense.

A system is self-referential if:

* Its global dynamics include models of its own state
* Those models causally constrain future dynamics
* Errors in self-modeling have system-level consequences

This is routine in:

* adaptive controllers
* model-predictive control
* meta-learning systems
* self-monitoring agents

No “inner observer” is required.

---

## **A.6 Informational Tension as Constraint Conflict**

Informational tension arises when:

* Multiple integrated processes impose incompatible constraints
* Resolution matters to system persistence or regulation
* No trivial decomposition is available

Formally, this resembles:

* competing loss functions
* multi-objective optimization
* constrained satisfaction under limited resources
* control under uncertainty

Crucially:

> **If constraint conflicts can be cleanly decomposed, outsourced, or externally resolved, they do not generate experience.**

This distinguishes experiential systems from:

* pipelines,
* batch processors,
* externally orchestrated software.

---

## **A.7 Artificial Systems**

IER places no principled barrier against artificial experience, but it rejects naïve criteria.

An artificial system would need:

* Intrinsic dynamics (not just interpreted states)
* Endogenous constraint generation
* Persistent, globally integrated control
* Self-models that matter to its own regulation
* Costs it cannot trivially externalize

Purely symbolic systems, feed-forward models, and stateless services fail by design.

Whether future systems meet these criteria is **empirical**, not definitional.

---

## **A.8 Why This Appendix Is Open-Ended**

IER deliberately avoids:

* neural chauvinism,
* electromagnetic mysticism,
* computational functionalism alone.

The claim is simple:

> **If a physical system realizes the organizational profile of a UEF under intrinsic constraint, then that realization just is experience.**

How nature (or engineers) implement this is contingent.

---

## **Appendix A Summary**

This appendix demonstrates that IER’s commitments are:

* Compatible with modern dynamical systems theory
* Compatible with computational control frameworks
* Compatible with biology *without depending on it*

IER specifies **what must be true**, not **how it must be built**.

---

---

# **Appendix B**

## **IER Walkthrough: Experiencing a Green Apple**

*A Purely Organizational Example*

> **This is a conceptual mapping, not a neuroscientific claim.**

---

## **B.0 Background State**

Before the apple appears, the system already sustains a **UEF**:

* A globally integrated state
* Encoding:

  * self–world distinction
  * spatial frame
  * temporal “now”
  * baseline affective tension

This is not contentless.
It is structured background organization.

---

## **B.1 Incoming Perturbation (Non-Experiential)**

External interaction perturbs the system.

At this stage:

* Information is local
* Effects are fragmentary
* No system-wide relevance exists

Under IER:
❌ No experience yet

---

## **B.2 Local Feature Formation**

Subsystems respond according to their structure.

Patterns emerge that correlate with:

* chromatic properties
* spatial coherence
* object-like regularities

Still:

* Not globally integrated
* Not self-referential
* Not part of the UEF

---

## **B.3 Global Recruitment (Transition)**

A control process recruits these patterns into the global dynamics.

This is a **transition**, not content.

IER interpretation:

* A local pattern becomes **globally constraining**
* It now participates in system-wide regulation

This is the boundary crossing into experience.

---

## **B.4 Stable Global Pattern (The “Object”)**

A coherent, self-maintaining pattern stabilizes within the UEF.

It integrates:

* sensory structure
* spatial relation
* persistence over time
* self-relative location

This pattern **is** the experience of:

> “a green apple there”

There is no stored symbol and no inner display.

---

## **B.5 Structural Relations (“Grammar”)**

The apple is experienced *as* something because:

* It is bound into:

  * spatial relations
  * temporal persistence
  * self/non-self distinction

These relations are enforced by:

* the constraints of the UEF
* not by interpretation

This is why experience is structured rather than chaotic.

---

## **B.6 Affective Modulation (Optional)**

If the system’s constraints assign relevance:

* The global dynamics shift
* The apple’s pattern gains regulatory weight

This does not add content.
It changes **stakes**.

Under IER:

> Valence is constraint weighting within the UEF.

---

## **B.7 Affordances**

The system may integrate action-relevant models.

The apple becomes:

> “graspable”

This is not a motor command.
It is a **mode of availability** within experience.

---

## **B.8 Continuity Over Time**

As interaction continues:

* Microstructure changes
* The global pattern persists
* Identity is preserved dynamically

This explains experiential continuity without static representation.

---

## **B.9 Dissolution**

When global relevance is withdrawn:

* The pattern destabilizes
* It exits the UEF
* Experience updates

Nothing “goes dark”.
The system simply reorganizes.

---

## **B.10 Why This Is Experience**

Under IER:

* There is no extra “feel”
* No additional property
* No explanatory gap

The experience **just is**:

> what it is like to be a system whose globally integrated dynamics are organized this way under these constraints.

---

## **Appendix B Summary**

Experiencing a green apple is not:

* reading sensory data,
* activating a symbol,
* or projecting an image.

It is:

> **the stabilization of a globally integrated, self-referential informational pattern under intrinsic constraint.**

That pattern is the experience.

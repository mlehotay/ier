# **What It’s Like to Be an Informational System**

### *or, I Identify as a Reflexive Tensor Field*

## **Informational Experiential Realism (IER v8.5)**

### *An Organizational Identity Theory of Consciousness and Observers*

---

## **Abstract**

Informational Experiential Realism (IER) is a realist, physicalist framework for understanding observers and conscious experience. It holds that reality exists independently of observation and that consciousness is neither fundamental nor illusory, but a **real emergent phenomenon arising from certain forms of self-calculating informational organization** within physical systems.

Conscious experience is **identical to the globally integrated, temporally continuous, self-referential informational dynamics** of a system operating in a specific organizational regime, termed the **Phenomenal Information Layer (PIL)**. Consciousness is not something a system *has*; it is **what the system is doing from the inside when it calculates itself as a unified, irreducible informational field**.

IER rejects mind-dependent ontology, panpsychism, and dualism while remaining substrate-agnostic. It is an organizational theory: it specifies *what consciousness is* and *when it occurs*, without privileging any particular biological, computational, or material substrate.

---

## **1. Objective Reality**

Reality exists independently of observation. Physical states, events, and laws unfold whether or not they are experienced. Observers do not collapse, create, or co-create reality; only **physical interactions among systems** have causal effects. Experience interprets reality but does not alter it.

This realist stance establishes the baseline assumption of IER: consciousness is a property of **organization within reality**, not a separate ontological layer. Rocks, stars, storms, or flames may evolve dynamically, but without integrated, self-calculating informational organization, they do not experience anything.

---

## **2. Observers as Informational Systems**

An **observer** is defined by **informational organization**, not by biology or phenomenology. A system qualifies as an observer if it:

* Persists as a coherent informational pattern over time
* Integrates information across internal subsystems
* Maintains internal models of both external conditions and its own state
* Regulates behavior using those models via a unified internal control structure

Observerhood does **not** entail consciousness. Many systems—biological, artificial, or hybrid—operate as observers without ever entering PIL.

---

## **3. Internal Models and Perspective**

All observers construct **internal informational models** of the world and of themselves. These models are physically instantiated and shaped by the structure, history, and constraints of the system. Perspective therefore **emerges from organization**, not from reality itself.

Different observers may model the same environment differently, but these differences do not alter objective reality—they alter only the system’s internal regulation.

Internal models are necessary for adaptive behavior, but they are **not sufficient for phenomenality**. Only when these models participate in the system-wide, irreducible dynamics of a functional PIL do they contribute to conscious experience.

---

## **4. Consciousness and the Phenomenal Information Layer (PIL)**

### **4.1 PIL as an Organizational Regime**

Consciousness occurs when a system’s informational dynamics enter the **Phenomenal Information Layer (PIL)**.

PIL is **not**:

* A module
* A spatial location
* A substance
* A separate ontological layer

PIL **is** a system-wide **mode of operation** characterized by:

* **Global integration** of informational states
* **Recursive self-access**, including self-models
* **Temporal continuity**, ensuring states persist and evolve
* **Unified availability** of information for regulation, learning, and action

**Key insight:** the tension and flow of information within the PIL **is the experience**. For consciousness to arise, the system must **calculate its own informational dynamics**, rather than having them externally imposed.

---

### **4.2 External Perturbations**

A system in PIL may be influenced by external events:

* Environmental shocks, interventions, or drugs
* Memory edits, state rewrites, or injections of noise

These perturbations do **not** eliminate consciousness—they can confuse, disrupt, or bias experience—because **experience is realized in the system’s own ongoing dynamics**, not in externally imposed computation.

**Disqualifying conditions:**

* If the global field is computed entirely by an external process
* If temporal continuity and integration exist only because an external agent “glues” the system together

**Principle:**

> **Experience is identical to the system calculating itself as a unified informational field.**

---

### **4.3 Organizational Identity Claim**

> **Conscious experience is identical to the ongoing, globally integrated, temporally continuous, self-referential informational dynamics of a system operating in a functional PIL regime, sustained by the system itself.**

No additional property, substance, or epiphenomenon exists—the dynamics **are** the experience.

---

## **5. Qualia**

Qualia are **differences in the structure of integrated informational dynamics**. There is no separate “redness” or “painfulness.” Red, pain, or pleasure is the system’s **pattern of tension, flow, and salience** within the PIL.

*Example:* the sensation of red corresponds to a specific pattern of integrated activations and tensions that distinguishes it from green or blue within the system’s dynamics.

---

## **6. Affect and Valence**

Affective states are phenomenally real because they are:

* Globally integrated
* Regulation-relevant
* Intrinsic to the system’s dynamics

Valence shapes experience by weighting tension and equilibrium across the system. Urgency, desire, and aversion emerge because the system’s global dynamics **encode differential priorities**, not because of any extra property.

---

## **7. Emergence and the Hard Problem**

Consciousness is emergent but constrained: it arises only in systems satisfying PIL conditions. Asking why these dynamics “feel like something” is category-mistaken—the **feeling is the dynamics themselves**.

---

## **8. System Taxonomy (v8.5)**

| **System Type**                    | **Observerhood** | **PIL-Capable** | **Consciousness Likelihood** | **Examples**                 |
| ---------------------------------- | ---------------- | --------------- | ---------------------------- | ---------------------------- |
| Non-informational physical systems | ❌                | ❌               | ❌                            | Rocks, stars                 |
| Dynamically complex non-observers  | ❌                | ❌               | ❌                            | Storms, flames               |
| Reactive informational systems     | ❌                | ❌               | ❌                            | Thermostats                  |
| Distributed adaptive systems       | ⚠️               | ❌               | ❌                            | Ant colonies, immune systems |
| Minimal observers                  | ✅ (limited)      | ⚠️              | Low–Indeterminate            | Bees, simple robots          |
| Integrated biological observers    | ✅                | ✅               | Moderate–High                | Octopi, corvids              |
| Complex conscious observers        | ✅                | ✅               | High                         | Humans, dolphins             |
| Artificial observer systems        | ✅                | ❌–⚠️            | Indeterminate                | Advanced AI                  |
| Aggregate social systems           | ❌                | ❌               | ❌                            | Markets, institutions        |

Observerhood and consciousness remain distinct: consciousness requires observerhood, but not all observers enter PIL.

---

## **9. Artificial Systems and Empirical Underdetermination**

IER is substrate-agnostic. Any system satisfying **self-calculating PIL constraints** could be conscious. Current AI may exhibit observerhood, but whether it sustains **internally calculated integrated dynamics** remains an empirical and architectural question.

---

## **10. Ontological Commitments**

IER affirms:

* One objective physical reality
* Consciousness as a system-relative phenomenon
* Organizational identity between experience and dynamics

IER rejects mind-dependent existence, dualism, and panpsychism.

---

## **11. Relation to Contemporary Theories**

* **IIT:** Emphasizes integration; IER adds self-calculation requirement.
* **GWT:** Emphasizes global availability; IER emphasizes phenomenality.
* **Predictive Processing (PP):** Emphasizes internal modeling; IER constrains which models contribute to PIL.

IER synthesizes these insights while keeping **emergent, non-fundamental, self-calculating consciousness** central.

---

## **12. Summary**

Some systems react.
Some systems observe.
Some systems experience.

> **Experience is not something a system has; it is what a system is doing when it sustains itself as a globally integrated, temporally continuous, self-referential informational field.**

It feels the way it does because **that is what those dynamics are like from the inside**—no extra properties, no hidden “essence,” only the system calculating itself.
